{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, ChebConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainConnectivityDataset(Dataset):\n",
    "    def __init__(self, data_dir, edge_modalities, node_modalities=None, additional_variables=None, scaling=True):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.edge_modalities = edge_modalities\n",
    "        self.node_modalities = node_modalities if node_modalities else []\n",
    "        self.additional_variables = additional_variables if additional_variables else []\n",
    "        self.scaling = scaling\n",
    "        self.df = pd.read_csv(os.path.join(data_dir, 'Subjects.csv'))\n",
    "        self.subjects = self.df['No'].to_numpy()\n",
    "    def len(self):\n",
    "        return len(self.subjects)\n",
    "    def get(self, idx):\n",
    "        subject = self.subjects[idx]\n",
    "        edge_index_list = []\n",
    "        edge_attr_list = []\n",
    "        for modality in self.edge_modalities:\n",
    "            conn_matrix = pd.read_csv(\n",
    "                os.path.join(self.data_dir, modality, f\"{subject:03d}.csv\"),\n",
    "                header=None).values\n",
    "            if not conn_matrix.shape[0] == conn_matrix.shape[1]:\n",
    "                raise ValueError(f\"Non-square connectivity matrix found in {modality}\")\n",
    "            if self.scaling:\n",
    "                conn_matrix = self._scale_data(conn_matrix)\n",
    "            edge_index, edge_attr = self._matrix_to_edge_index_attr(conn_matrix)\n",
    "            edge_index_list.append(edge_index)\n",
    "            edge_attr_list.append(edge_attr)\n",
    "        node_features_list = []\n",
    "        if self.node_modalities:\n",
    "            for modality in self.node_modalities:\n",
    "                node_features = pd.read_csv(\n",
    "                    os.path.join(self.data_dir, modality, f\"{subject:03d}.csv\"),\n",
    "                    header=None).values\n",
    "                if self.scaling:\n",
    "                    node_features = self._scale_data(node_features)\n",
    "                node_features_list.append(torch.tensor(node_features, dtype=torch.float))\n",
    "        else:\n",
    "            node_features_list = []\n",
    "            for modality in self.edge_modalities:\n",
    "                conn_matrix = pd.read_csv(\n",
    "                    os.path.join(self.data_dir, modality, f\"{subject:03d}.csv\"),\n",
    "                    header=None).values\n",
    "                if self.scaling:\n",
    "                    conn_matrix = self._scale_data(conn_matrix)\n",
    "                node_features_list.append(torch.tensor(conn_matrix, dtype=torch.float))\n",
    "        node_features = torch.cat(node_features_list, dim=1)\n",
    "        if not all(torch.equal(edge_index_list[0], edge_idx) for edge_idx in edge_index_list[1:]):\n",
    "            raise ValueError(f\"Different graph structures detected for subject {subject}\")\n",
    "        edge_attr = torch.cat(edge_attr_list, dim=1)\n",
    "        additional_features = torch.tensor([\n",
    "            self.df[var][idx] for var in self.additional_variables \n",
    "            if var != 'Sex'\n",
    "        ], dtype=torch.float).view(1, -1)\n",
    "        label = torch.tensor(self.df['Sex'][idx], dtype=torch.long) if 'Sex' in self.df.columns else None\n",
    "        return Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index_list[0],\n",
    "            edge_attr=edge_attr,\n",
    "            additional_features=additional_features,\n",
    "            y=label,\n",
    "            num_nodes=node_features.shape[0]\n",
    "        )\n",
    "    def load_data(self, batch_size, inference=False, test_size=0.2):\n",
    "        if inference:\n",
    "            test_loader = DataLoader(self, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "            subjects = self.subjects\n",
    "            return test_loader, subjects\n",
    "        else:\n",
    "            indices = list(range(len(self)))\n",
    "            labels = [self[i].y.item() for i in indices]\n",
    "            train_indices, val_indices = train_test_split(indices, test_size=test_size, stratify=labels, random_state=42)\n",
    "            train_ds = Subset(self, train_indices)\n",
    "            val_ds = Subset(self, val_indices)\n",
    "            train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "            val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "            return train_loader, val_loader, train_ds, val_ds\n",
    "    def _calculate_degree(self, matrix, binary=True):\n",
    "        if binary:\n",
    "            matrix = (matrix != 0).astype(float)\n",
    "        return np.sum(matrix, axis=1, keepdims=True)\n",
    "    def _scale_data(self, data):\n",
    "        if data.ndim == 2 and data.shape[0] == data.shape[1]:\n",
    "            is_matrix=True\n",
    "        else:\n",
    "            is_matrix=False\n",
    "        if is_matrix:\n",
    "            values = data[~np.eye(data.shape[0], dtype=bool)]\n",
    "        else:\n",
    "            values = data.flatten()\n",
    "        absmax = np.abs(values).max()\n",
    "        scaled_data = data / (absmax + 1e-8)\n",
    "        if is_matrix:\n",
    "            scaled_data[np.eye(scaled_data.shape[0], dtype=bool)] = 1\n",
    "        return scaled_data\n",
    "    def _matrix_to_edge_index_attr(self, matrix):\n",
    "        num_nodes_per_graph = matrix.shape[0]\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for i in range(num_nodes_per_graph):\n",
    "            for j in range(num_nodes_per_graph):\n",
    "                if i != j:\n",
    "                    edge_index.append([i, j])\n",
    "                    edge_attr.append(matrix[i, j])\n",
    "        return (torch.tensor(edge_index, dtype=torch.long).t(),\n",
    "                torch.tensor(edge_attr, dtype=torch.float).view(-1, 1))\n",
    "\n",
    "class BrainGCNConv(GCNConv):\n",
    "    def __init__(self, in_channels, out_channels, num_nodes_per_graph, num_edge_features, modality_weights=None):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.num_nodes_per_graph = num_nodes_per_graph\n",
    "        if modality_weights is None:\n",
    "            self.modality_weights = nn.Parameter(torch.ones(num_edge_features))\n",
    "        else:\n",
    "            self.modality_weights = nn.Parameter(modality_weights)\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        if edge_weight is not None and edge_weight.dim() > 1:\n",
    "            modality_weights = F.softmax(self.modality_weights, dim=0)\n",
    "            outputs = []\n",
    "            num_modalities = edge_weight.size(1)\n",
    "            num_nodes_per_graph = self.num_nodes_per_graph\n",
    "            for i in range(num_modalities):\n",
    "                modality_weight = edge_weight[:, i] * modality_weights[i]\n",
    "                if x.size(1) == num_nodes_per_graph * num_modalities:\n",
    "                    x_modality = x[:, i*num_nodes_per_graph:(i+1)*num_nodes_per_graph]\n",
    "                elif x.size(1) == num_modalities:\n",
    "                    x_modality = x[:, i:i+1]\n",
    "                else:\n",
    "                    x_modality = x\n",
    "                outputs.append(super().forward(x_modality, edge_index, modality_weight))\n",
    "            return torch.mean(torch.stack(outputs), dim=0)\n",
    "        else:\n",
    "            return super().forward(x, edge_index, edge_weight)\n",
    "        \n",
    "class BrainGATConv(GATConv):\n",
    "    def __init__(self, in_channels, out_channels, num_nodes_per_graph, num_edge_features, modality_weights=None, **kwargs):\n",
    "        heads = kwargs.get('heads', 1)\n",
    "        super().__init__(in_channels, out_channels, heads=heads, concat=True)\n",
    "        self.num_nodes_per_graph = num_nodes_per_graph\n",
    "        if modality_weights is None:\n",
    "            self.modality_weights = nn.Parameter(torch.ones(num_edge_features))\n",
    "        else:\n",
    "            self.modality_weights = nn.Parameter(modality_weights)\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        if edge_weight is not None and edge_weight.dim() > 1:\n",
    "            modality_weights = F.softmax(self.modality_weights, dim=0)\n",
    "            outputs = []\n",
    "            num_modalities = edge_weight.size(1)\n",
    "            num_nodes_per_graph = self.num_nodes_per_graph\n",
    "            for i in range(num_modalities):\n",
    "                modality_weight = edge_weight[:, i] * modality_weights[i]\n",
    "                if x.size(1) == num_nodes_per_graph * num_modalities:\n",
    "                    x_modality = x[:, i*num_nodes_per_graph:(i+1)*num_nodes_per_graph]\n",
    "                elif x.size(1) == num_modalities:\n",
    "                    x_modality = x[:, i:i+1]\n",
    "                else:\n",
    "                    x_modality = x\n",
    "                outputs.append(super().forward(x_modality, edge_index, edge_attr=modality_weight.unsqueeze(1)))\n",
    "            return torch.mean(torch.stack(outputs), dim=0)\n",
    "        else:\n",
    "            return super().forward(x, edge_index)\n",
    "\n",
    "class BrainSAGEConv(SAGEConv):\n",
    "    def __init__(self, in_channels, out_channels, num_nodes_per_graph, num_edge_features, modality_weights=None):\n",
    "        super().__init__(in_channels, out_channels, normalize=True)\n",
    "        self.num_nodes_per_graph = num_nodes_per_graph\n",
    "        if modality_weights is None:\n",
    "            self.modality_weights = nn.Parameter(torch.ones(num_edge_features))\n",
    "        else:\n",
    "            self.modality_weights = nn.Parameter(modality_weights)\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        if edge_weight is not None and edge_weight.dim() > 1:\n",
    "            modality_weights = F.softmax(self.modality_weights, dim=0)\n",
    "            outputs = []\n",
    "            num_modalities = edge_weight.size(1)\n",
    "            num_nodes_per_graph = self.num_nodes_per_graph\n",
    "            for i in range(num_modalities):\n",
    "                modality_weight = edge_weight[:, i] * modality_weights[i]\n",
    "                if x.size(1) == num_nodes_per_graph * num_modalities:\n",
    "                    x_modality = x[:, i*num_nodes_per_graph:(i+1)*num_nodes_per_graph]\n",
    "                elif x.size(1) == num_modalities:\n",
    "                    x_modality = x[:, i:i+1]\n",
    "                else:\n",
    "                    x_modality = x\n",
    "                x_j = self.lin_r(x_modality)\n",
    "                out = self.propagate(edge_index, x=x_modality, edge_weight=modality_weight)\n",
    "                out = self.lin_l(out)\n",
    "                out = out + x_j\n",
    "                if self.normalize:\n",
    "                    out = F.normalize(out, p=2., dim=-1)\n",
    "                outputs.append(out)\n",
    "            return torch.mean(torch.stack(outputs), dim=0)\n",
    "        else:\n",
    "            x_j = self.lin_r(x)\n",
    "            out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "            out = self.lin_l(out)\n",
    "            out = out + x_j\n",
    "            if self.normalize:\n",
    "                out = F.normalize(out, p=2., dim=-1)  \n",
    "            return out\n",
    "\n",
    "class BrainChebConv(ChebConv):\n",
    "    def __init__(self, in_channels, out_channels, num_nodes_per_graph, num_edge_features, modality_weights=None, K=2):\n",
    "        super().__init__(in_channels, out_channels, K=K)\n",
    "        self.num_nodes_per_graph = num_nodes_per_graph\n",
    "        if modality_weights is None:\n",
    "            self.modality_weights = nn.Parameter(torch.ones(num_edge_features))\n",
    "        else:\n",
    "            self.modality_weights = nn.Parameter(modality_weights)\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        if edge_weight is not None and edge_weight.dim() > 1:\n",
    "            modality_weights = F.softmax(self.modality_weights, dim=0)\n",
    "            outputs = []\n",
    "            num_modalities = edge_weight.size(1)\n",
    "            num_nodes_per_graph = self.num_nodes_per_graph\n",
    "            for i in range(num_modalities):\n",
    "                modality_weight = edge_weight[:, i] * modality_weights[i]\n",
    "                if x.size(1) == num_nodes_per_graph * num_modalities:\n",
    "                    x_modality = x[:, i*num_nodes_per_graph:(i+1)*num_nodes_per_graph]\n",
    "                elif x.size(1) == num_modalities:\n",
    "                    x_modality = x[:, i:i+1]\n",
    "                else:\n",
    "                    x_modality = x\n",
    "                outputs.append(super().forward(x_modality, edge_index, modality_weight))\n",
    "            return torch.mean(torch.stack(outputs), dim=0)\n",
    "        else:\n",
    "            return super().forward(x, edge_index, edge_weight)\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels}, K={self.K})'\n",
    "\n",
    "class BrainGNN(torch.nn.Module):\n",
    "    def __init__(self, conv_layer, num_nodes_per_graph, num_node_features, num_edge_features, num_additional_features,\n",
    "                 num_channels=[32, 32, 64, 64, 128], modality_weights=None, **kwargs):\n",
    "        super().__init__()\n",
    "        K = kwargs.get('K', 2) # ChebNet\n",
    "        heads = kwargs.get('heads', 4)  # GAT\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        ConvLayer = self._get_conv_layer(conv_layer)\n",
    "        if conv_layer == \"GAT\":\n",
    "            for channel in num_channels:\n",
    "                if channel % heads != 0:\n",
    "                    raise ValueError(f\"All channel numbers must be divisible by number of heads ({heads})\")\n",
    "            channels_to_use = [c // heads for c in num_channels]\n",
    "        else:\n",
    "            channels_to_use = num_channels\n",
    "        conv_params = {\n",
    "            'num_nodes_per_graph': num_nodes_per_graph, \n",
    "            'num_edge_features': num_edge_features,\n",
    "            'modality_weights': modality_weights\n",
    "        }\n",
    "        if conv_layer == \"ChebNet\":\n",
    "            conv_params['K'] = K  \n",
    "        if conv_layer == \"GAT\":\n",
    "            conv_params['heads'] = heads\n",
    "        self.conv_layers.append(\n",
    "            ConvLayer(num_node_features, channels_to_use[0], **conv_params)\n",
    "        )\n",
    "        for i in range(len(channels_to_use) - 1):\n",
    "            num_in_channels = channels_to_use[i] * (heads if conv_layer == \"GAT\" else 1)\n",
    "            self.conv_layers.append(\n",
    "                ConvLayer(num_in_channels, channels_to_use[i + 1], **conv_params)\n",
    "            )\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for i, channel in enumerate(channels_to_use):\n",
    "            if conv_layer == \"GAT\":\n",
    "                self.batch_norms.append(nn.BatchNorm1d(channel * heads))\n",
    "            else:\n",
    "                self.batch_norms.append(nn.BatchNorm1d(channel))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        num_final_channels = channels_to_use[-1] * (heads if conv_layer == \"GAT\" else 1)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(num_final_channels + num_additional_features, num_final_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(num_final_channels // 2, num_final_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(num_final_channels // 4, 2)\n",
    "        )\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        for i, (conv, bn) in enumerate(zip(self.conv_layers, self.batch_norms)):\n",
    "            identity = x\n",
    "            x = conv(x, data.edge_index, data.edge_attr)\n",
    "            x = bn(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            if i > 0 and x.size() == identity.size():\n",
    "                x = x + identity\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        x = torch.cat([x, data.additional_features], dim=1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    def _get_conv_layer(self, conv_layer):\n",
    "        conv_layers = {\n",
    "            \"GCN\": BrainGCNConv,\n",
    "            \"GAT\": BrainGATConv,\n",
    "            \"GraphSAGE\": BrainSAGEConv,\n",
    "            \"ChebNet\": BrainChebConv,\n",
    "        }\n",
    "        if conv_layer not in conv_layers:\n",
    "            raise ValueError(f\"Unsupported convolution layer: {conv_layer}\")\n",
    "        return conv_layers[conv_layer]\n",
    "\n",
    "def get_model(model_name, num_nodes_per_graph, num_node_features, num_edge_features, num_additional_features,\n",
    "              num_channels=[32, 32, 64, 64, 128], modality_weights=None):\n",
    "    if model_name == \"GCN\":\n",
    "        return BrainGNN(\n",
    "            conv_layer=\"GCN\",\n",
    "            num_nodes_per_graph=num_nodes_per_graph,\n",
    "            num_node_features=num_node_features,\n",
    "            num_edge_features=num_edge_features,\n",
    "            num_additional_features=num_additional_features,\n",
    "            num_channels=num_channels,\n",
    "            modality_weights=modality_weights,\n",
    "        )\n",
    "    elif model_name == \"GAT\":\n",
    "        return BrainGNN(\n",
    "            conv_layer=\"GAT\",\n",
    "            num_nodes_per_graph=num_nodes_per_graph,\n",
    "            num_node_features=num_node_features,\n",
    "            num_edge_features=num_edge_features,\n",
    "            num_additional_features=num_additional_features,\n",
    "            num_channels=num_channels,\n",
    "            modality_weights=modality_weights,\n",
    "            heads=4\n",
    "        )\n",
    "    elif model_name == \"GraphSAGE\":\n",
    "        return BrainGNN(\n",
    "            conv_layer=\"GraphSAGE\",\n",
    "            num_nodes_per_graph=num_nodes_per_graph,\n",
    "            num_node_features=num_node_features,\n",
    "            num_edge_features=num_edge_features,\n",
    "            num_additional_features=num_additional_features,\n",
    "            num_channels=num_channels,\n",
    "            modality_weights=modality_weights\n",
    "        )\n",
    "    elif model_name == \"ChebNet\":\n",
    "        return BrainGNN(\n",
    "            conv_layer=\"ChebNet\",\n",
    "            num_nodes_per_graph=num_nodes_per_graph,\n",
    "            num_node_features=num_node_features,\n",
    "            num_edge_features=num_edge_features,\n",
    "            num_additional_features=num_additional_features,\n",
    "            num_channels=num_channels,\n",
    "            modality_weights=modality_weights,\n",
    "            K=2\n",
    "        )\n",
    "\n",
    "def visualize_conn_matrix(sample, edge_modalities, title=None):\n",
    "    _, axs = plt.subplots(1, len(edge_modalities), figsize=(len(edge_modalities) * 4, 4), squeeze=False)\n",
    "    batch_size = len(sample.ptr) - 1\n",
    "    num_nodes_per_graph = sample.num_nodes // batch_size\n",
    "    num_edges_per_graph = sample.edge_index.size(1) // batch_size \n",
    "    for col, modality in enumerate(edge_modalities):\n",
    "        edge_attr = sample.edge_attr[:num_edges_per_graph, col]\n",
    "        edge_index = sample.edge_index[:, :num_edges_per_graph]\n",
    "        conn_matrix = torch.ones((num_nodes_per_graph, num_nodes_per_graph)).to(edge_attr.device)\n",
    "        conn_matrix[edge_index[0], edge_index[1]] = edge_attr\n",
    "        ax = axs[0, col]\n",
    "        matrix_numpy = conn_matrix.cpu().numpy()\n",
    "        abs_max = np.abs(matrix_numpy).max()\n",
    "        im = ax.imshow(matrix_numpy, cmap='hot',\n",
    "                       vmin=-abs_max if np.any(matrix_numpy < 0) else 0, vmax=abs_max)\n",
    "        ax.set_title(f'{modality}')\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=12, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_one_epoch(model, device, train_loader, optimizer, criterion, scaler, metric):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    metric.reset()\n",
    "    for batch_data in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_data.y) \n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "        epoch_loss += loss.item()\n",
    "        metric(outputs[:, 1], batch_data.y)\n",
    "    epoch_metric = metric.compute().item()\n",
    "    return epoch_loss / len(train_loader), epoch_metric\n",
    "\n",
    "def validate_one_epoch(model, device, val_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for batch_data in val_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            outputs = model(batch_data)\n",
    "            metric(outputs[:, 1], batch_data.y)\n",
    "    return metric.compute().item()\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=30, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "    def __call__(self, metric):\n",
    "        score = metric\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "def train_model(model_dir, model, device, train_loader, val_loader, logger,\n",
    "        criterion, metric, max_epochs=100, learning_rate=1e-4, weight_decay=1e-5, val_interval=1, es_patience=30):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "    start_time = time.time()\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    early_stopping = EarlyStopping(patience=es_patience, delta=0)\n",
    "    epoch_loss_values, epoch_metric_values, metric_values = [], [], []\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_loss, epoch_metric = train_one_epoch(\n",
    "            model, device, train_loader, optimizer, criterion, scaler, metric)\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        epoch_metric_values.append(epoch_metric)\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            val_metric = validate_one_epoch(model, device, val_loader, metric)\n",
    "            metric_values.append(val_metric)\n",
    "            if val_metric > best_metric:\n",
    "                best_metric = val_metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                best_model_state = model.state_dict()\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, \"BestMetricModel.pth\"))\n",
    "                logger.info(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            early_stopping(val_metric)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                print(f\"; Early stopping triggered at epoch {epoch + 1}\", end=\"\")\n",
    "                break\n",
    "        epoch_end_time = time.time()\n",
    "        logger.info(f\"Epoch {epoch + 1} computed for {(epoch_end_time - epoch_start_time)/60:.2f} mins - Training loss: {epoch_loss:.4f}, Training accuracy: {epoch_metric:.4f}, Validation accuracy: {val_metric:.4f}\")\n",
    "        lr_scheduler.step()\n",
    "        sys.stdout.write(f\"\\rEpoch {epoch + 1}/{max_epochs} completed\")\n",
    "        sys.stdout.flush()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    logger.info(f\"Best accuracy: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
    "    print(f\"\\nBest accuracy: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model, epoch_loss_values, epoch_metric_values, metric_values\n",
    "\n",
    "def plot_metric_values(model_dir, epoch_loss_values, epoch_metric_values, metric_values, val_interval=1):\n",
    "    _, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].plot( [i + 1 for i in range(len(epoch_loss_values))], epoch_loss_values, label='Training Loss', color='red')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[1].plot([i + 1 for i in range(len(epoch_metric_values))], epoch_metric_values, label='Training Accuracy', color='red')\n",
    "    axs[1].plot([val_interval * (i + 1) for i in range(len(metric_values))], metric_values, label='Validation Accuracy', color='blue')\n",
    "    axs[1].set_title('Training Accuracy vs. Validation Accuracy')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(model_dir, \"Performance.png\"), dpi=300)\n",
    "\n",
    "def occlusion_based_sensitivity(model, sample, style='diverging', directed=False, window_size=10):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    sample = sample.to(device)\n",
    "    baseline_output = model(sample)\n",
    "    baseline_pred = F.softmax(baseline_output, dim=1)[0, 1].item()\n",
    "    num_nodes_per_graph = sample.num_nodes\n",
    "    sensitivity_matrix = torch.zeros((num_nodes_per_graph, num_nodes_per_graph), device=device)\n",
    "    if directed:\n",
    "        node_pairs = [(i, j) for i in range(num_nodes_per_graph) for j in range(num_nodes_per_graph) if i != j]\n",
    "    else:\n",
    "        node_pairs = [(i, j) for i in range(num_nodes_per_graph) for j in range(i+1, num_nodes_per_graph)]\n",
    "    for window_start in range(0, len(node_pairs), window_size):\n",
    "        window_end = min(window_start + window_size, len(node_pairs))\n",
    "        current_pairs = node_pairs[window_start:window_end]\n",
    "        temp_data = Data(\n",
    "            x=sample.x,\n",
    "            edge_index=sample.edge_index,\n",
    "            edge_attr=sample.edge_attr.clone(),\n",
    "            additional_features=sample.additional_features,\n",
    "            y=sample.y,\n",
    "            num_nodes=sample.num_nodes,\n",
    "            batch=sample.batch\n",
    "        ).to(device)\n",
    "        mask = torch.zeros_like(temp_data.edge_index[0], dtype=torch.bool)\n",
    "        for i, j in current_pairs:\n",
    "            if directed:\n",
    "                mask |= (temp_data.edge_index[0] == i) & (temp_data.edge_index[1] == j)\n",
    "            else:\n",
    "                mask |= ((temp_data.edge_index[0] == i) & (temp_data.edge_index[1] == j)) | \\\n",
    "                        ((temp_data.edge_index[0] == j) & (temp_data.edge_index[1] == i))\n",
    "        temp_data.edge_attr[mask] = 0\n",
    "        with torch.no_grad():\n",
    "            output = model(temp_data)\n",
    "            pred = F.softmax(output, dim=1)[0, 1].item()\n",
    "        if style == 'diverging':\n",
    "            sensitivity = pred - baseline_pred\n",
    "        elif style == 'absolute':\n",
    "            sensitivity = abs(pred - baseline_pred)\n",
    "        for i, j in current_pairs:\n",
    "            sensitivity_matrix[i, j] = sensitivity\n",
    "            if not directed:\n",
    "                sensitivity_matrix[j, i] = sensitivity\n",
    "    return sensitivity_matrix\n",
    "\n",
    "def occlusion_sensitivity_analysis(model, loader, model_dir, modalities, style='diverging', directed=False, num_samples=20):\n",
    "    accumulated_sensitivity = None\n",
    "    accumulated_samples = 0\n",
    "    sampling_complete = False\n",
    "    for batch_data in loader:\n",
    "        if sampling_complete:\n",
    "            break\n",
    "        batch_size = len(batch_data.ptr) - 1\n",
    "        for graph_idx in range(batch_size):\n",
    "            if accumulated_samples >= num_samples:\n",
    "                sampling_complete = True\n",
    "                break\n",
    "            start_idx = batch_data.ptr[graph_idx].item()\n",
    "            end_idx = batch_data.ptr[graph_idx + 1].item()\n",
    "            sample_x = batch_data.x[start_idx:end_idx, :]\n",
    "            edge_mask = (batch_data.edge_index[0] >= start_idx) & (batch_data.edge_index[0] < end_idx)\n",
    "            sample_edge_index = batch_data.edge_index[:, edge_mask] - start_idx\n",
    "            sample_edge_attr = batch_data.edge_attr[edge_mask, :]\n",
    "            sample_additional_features = batch_data.additional_features[graph_idx, :]\n",
    "            sample_y = batch_data.y[graph_idx]\n",
    "            sample_num_nodes = end_idx - start_idx\n",
    "            sample = Data(\n",
    "                x=sample_x,\n",
    "                edge_index=sample_edge_index,\n",
    "                edge_attr=sample_edge_attr,\n",
    "                additional_features=sample_additional_features.unsqueeze(-1),\n",
    "                y=sample_y,\n",
    "                num_nodes=sample_num_nodes,\n",
    "                batch=torch.zeros(sample_num_nodes, dtype=torch.long)\n",
    "            )\n",
    "            accumulated_samples += 1\n",
    "            sensitivity_matrix = occlusion_based_sensitivity(model, sample, style=style, directed=directed)\n",
    "            if accumulated_sensitivity is None:\n",
    "                accumulated_sensitivity = sensitivity_matrix\n",
    "            else:\n",
    "                accumulated_sensitivity += sensitivity_matrix\n",
    "    mean_sensitivity = accumulated_sensitivity / num_samples\n",
    "    df_sensitivity = pd.DataFrame(mean_sensitivity.cpu().numpy())\n",
    "    df_sensitivity.to_csv(os.path.join(model_dir, f\"SensitivityMap_{'_'.join(modalities)}.csv\"), index=False, header=False)\n",
    "    num_nodes_per_graph = mean_sensitivity.shape[0]\n",
    "    if directed:\n",
    "        values = mean_sensitivity.view(-1)\n",
    "        mask = ~torch.eye(num_nodes_per_graph, dtype=torch.bool, device=mean_sensitivity.device).view(-1)\n",
    "        values = values[mask]\n",
    "        abs_values = torch.abs(values)\n",
    "        threshold = torch.quantile(abs_values, 0.95)\n",
    "        high_sensitivity_pairs = []\n",
    "        for i in range(num_nodes_per_graph):\n",
    "            for j in range(num_nodes_per_graph):\n",
    "                if i != j and abs(mean_sensitivity[i, j]) >= threshold:\n",
    "                    high_sensitivity_pairs.append({\n",
    "                        'Node_i': i + 1,\n",
    "                        'Node_j': j + 1,\n",
    "                        'Sensitivity': mean_sensitivity[i, j].item()\n",
    "                    })\n",
    "    else:\n",
    "        upper_tri = torch.triu(mean_sensitivity, diagonal=1)\n",
    "        values = upper_tri.view(-1)\n",
    "        values = values[values != 0]\n",
    "        abs_values = torch.abs(values)\n",
    "        threshold = torch.quantile(abs_values, 0.95)\n",
    "        high_sensitivity_pairs = []\n",
    "        for i in range(num_nodes_per_graph):\n",
    "            for j in range(i+1, num_nodes_per_graph):\n",
    "                if abs(mean_sensitivity[i, j]) >= threshold:\n",
    "                    high_sensitivity_pairs.append({\n",
    "                        'Node_i': i + 1,\n",
    "                        'Node_j': j + 1,\n",
    "                        'Sensitivity': mean_sensitivity[i, j].item()\n",
    "                    })\n",
    "    df_top_pairs = pd.DataFrame(high_sensitivity_pairs)\n",
    "    df_top_pairs = df_top_pairs.sort_values('Sensitivity', key=abs, ascending=False)\n",
    "    df_top_pairs.to_csv(os.path.join(model_dir, f\"Top5PercentEdges_{'+'.join(modalities)}.csv\"), index=False)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sensitivity_numpy = mean_sensitivity.cpu().numpy()\n",
    "    heatmap_params = {\n",
    "        'xticklabels': False,\n",
    "        'yticklabels': False,\n",
    "        'square': True,\n",
    "    }\n",
    "    if style == 'diverging':\n",
    "        heatmap_params.update({\n",
    "            'cmap': 'RdBu_r',\n",
    "            'center': 0,\n",
    "            'vmin': -np.abs(sensitivity_numpy).max(),\n",
    "            'vmax': np.abs(sensitivity_numpy).max()\n",
    "        })\n",
    "    elif style == 'absolute':\n",
    "        heatmap_params.update({\n",
    "            'cmap': 'hot',\n",
    "            'vmin': 0,\n",
    "            'vmax': sensitivity_numpy.max()\n",
    "        })\n",
    "    sns.heatmap(sensitivity_numpy, **heatmap_params)\n",
    "    plt.title(f\"Sensitivity Map: {'+'.join(modalities)}\", fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(model_dir, f\"Sensitivity_{'+'.join(modalities)}.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def visualize_brain_network(model_dir, atlas_path, modalities, directed=False):\n",
    "    edges_filename = f\"Top5PercentEdges_{'+'.join(modalities)}.csv\"\n",
    "    edges_path = os.path.join(model_dir, edges_filename)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    edges_df['Node_i'] = edges_df['Node_i'] - 1\n",
    "    edges_df['Node_j'] = edges_df['Node_j'] - 1\n",
    "    atlas_img = nib.load(atlas_path)\n",
    "    coords = plotting.find_parcellation_cut_coords(atlas_img)\n",
    "    n_nodes = len(coords)\n",
    "    connectivity_matrix = np.zeros((n_nodes, n_nodes))\n",
    "    max_abs_sensitivity = np.abs(edges_df['Sensitivity']).max()\n",
    "    edges_df['Scaled_Sensitivity'] = edges_df['Sensitivity'] / max_abs_sensitivity\n",
    "    for _, row in edges_df.iterrows():\n",
    "        i, j = int(row['Node_i']), int(row['Node_j'])\n",
    "        connectivity_matrix[i, j] = row['Scaled_Sensitivity']\n",
    "        if not directed:\n",
    "            connectivity_matrix[j, i] = row['Scaled_Sensitivity']\n",
    "    if directed:\n",
    "        out_sensitivity = np.sum(connectivity_matrix, axis=1)\n",
    "        in_sensitivity = np.sum(connectivity_matrix, axis=0)\n",
    "        node_sensitivity =  np.mean([out_sensitivity, in_sensitivity], axis=0)\n",
    "    else:\n",
    "        node_sensitivity = np.sum(connectivity_matrix, axis=1)\n",
    "    max_abs_node_sensitivity = np.abs(node_sensitivity).max()\n",
    "    node_sensitivity = node_sensitivity / max_abs_node_sensitivity\n",
    "    node_colors = np.zeros((n_nodes, 3))\n",
    "    positive_mask = node_sensitivity > 0\n",
    "    negative_mask = node_sensitivity < 0\n",
    "    node_colors[positive_mask] = np.array([1, 0, 0])\n",
    "    node_colors[negative_mask] = np.array([0, 0, 1])\n",
    "    node_colors *= np.abs(node_sensitivity)[:, np.newaxis]\n",
    "    alpha = 0.3\n",
    "    node_colors = [(plt.cm.colors.to_rgba(c, alpha)) for c in node_colors]\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plotting.plot_connectome(\n",
    "        connectivity_matrix, coords,\n",
    "        node_color=node_colors,\n",
    "        node_size=100 * np.abs(node_sensitivity) + 20,\n",
    "        edge_cmap='seismic',\n",
    "        edge_vmin=-1,\n",
    "        edge_vmax=1,\n",
    "        colorbar=True,\n",
    "        edge_threshold=None,\n",
    "        annotate=False,\n",
    "        black_bg=False\n",
    "    )\n",
    "    plt.suptitle(\"Connectional and regional sensitivity\", bbox=dict(facecolor='white', edgecolor=None))\n",
    "    sizes = [0.3, 0.6, 0.9]\n",
    "    legend_elements = [plt.scatter([], [], c='black', s=(100 * s + 20), label=f'Node sensitivity: {s:.1f}') for s in sizes]\n",
    "    plt.legend(handles=legend_elements, loc='best', \n",
    "              title='Node size scale', frameon=True, \n",
    "              facecolor='white', edgecolor='black', labelcolor='black')\n",
    "    bn_path = os.path.join(model_dir, f\"Top5PercentEdges_{'+'.join(modalities)}_BrainNetwork.tif\")\n",
    "    plt.savefig(bn_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(\"\\nNetwork summary:\")\n",
    "    print(f\"Number of nodes: {n_nodes}\")\n",
    "    print(f\"Number of edges: {len(edges_df)}\")\n",
    "    print(f\"Maximum absolute sensitivity: {max_abs_sensitivity:.6f}\")\n",
    "    print(f\"Nodes with highest positive sensitivity:\")\n",
    "    top_positive = np.argsort(node_sensitivity)[-5:][::-1]\n",
    "    for node in top_positive:\n",
    "        print(f\"Node {node+1}: {node_sensitivity[node]:.3f}\")\n",
    "    print(f\"Nodes with lowest negative sensitivity:\")\n",
    "    top_negative = np.argsort(node_sensitivity)[:5]\n",
    "    for node in top_negative:\n",
    "        print(f\"Node {node+1}: {node_sensitivity[node]:.3f}\")\n",
    "\n",
    "def apply_best_model(model_dir, model, device, test_loader, pred_dir, subjects):\n",
    "    model.load_state_dict(torch.load(os.path.join(model_dir, \"BestMetricModel.pth\")))\n",
    "    model.eval()\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "    prob_values = np.array([])\n",
    "    pred_values = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            outputs = model(batch_data)\n",
    "            pred_probs = F.softmax(outputs, dim=1)\n",
    "            pred_labels = torch.argmax(pred_probs, dim=1)\n",
    "            prob_values = np.append(prob_values, pred_probs[:, 1].cpu().numpy())\n",
    "            pred_values = np.append(pred_values, pred_labels.cpu().numpy())\n",
    "    df = pd.DataFrame({\n",
    "        'No': subjects,\n",
    "        'Pr': prob_values,\n",
    "        'PredSex': pred_values\n",
    "    })\n",
    "    df.to_csv(os.path.join(pred_dir, \"PredSex.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"SexClassification\"\n",
    "model_dir_prefix = \"SexClassification\"\n",
    "model_name = \"GCN\" # any supported model name: GCN, GAT, GraphSAGE, ChebNet\n",
    "edge_modalities = [\"PC\", \"Count\"]\n",
    "node_modalities = None\n",
    "additional_variables = [\"Sex\", \"Age\"]\n",
    "test_size = 0.2\n",
    "scaling = True\n",
    "num_channels = [32, 32, 64, 64, 128]\n",
    "batch_size = 32\n",
    "max_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 5e-4\n",
    "val_interval = 1\n",
    "es_patience = 30\n",
    "\n",
    "model_dir = f\"{model_dir_prefix}_{model_name}\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Device:', device)\n",
    "log_file = os.path.join(model_dir, \"Prediction.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BrainConnectivityDataset(\n",
    "    data_dir=os.path.join(data_dir, \"train\"),\n",
    "    edge_modalities=edge_modalities,\n",
    "    node_modalities=node_modalities,\n",
    "    additional_variables=additional_variables,\n",
    "    scaling=scaling\n",
    ")\n",
    "train_loader, val_loader, train_ds, val_ds = ds.load_data(batch_size=batch_size, inference=False, test_size=test_size)\n",
    "\n",
    "# Check data shape\n",
    "tr = next(iter(train_loader))\n",
    "num_nodes_per_graph = tr.num_nodes // batch_size\n",
    "if node_modalities:\n",
    "    if len(node_modalities) == len(edge_modalities):\n",
    "        num_node_features = tr.x.shape[1] // len(node_modalities)\n",
    "    else:\n",
    "        num_node_features = tr.x.shape[1]\n",
    "else:\n",
    "    num_node_features = num_nodes_per_graph\n",
    "print('Data shape for training:')\n",
    "print(f'\\u2022 Node features: ({batch_size} \\u00D7 {tr.x.shape[0] // batch_size}, {tr.x.shape[1]}) \\u00D7 {len(train_loader)}')\n",
    "print(f'\\u2022 Edge features: ({batch_size} \\u00D7 {tr.edge_attr.shape[0] // batch_size}, {tr.edge_attr.shape[1]}) \\u00D7 {len(train_loader)}')\n",
    "print(f'\\u2022 Additional features: {tuple(tr.additional_features.shape)} \\u00D7 {len(train_loader)}')\n",
    "print(f'\\u2022 Labels: {tuple(tr.y.shape)} \\u00D7 {len(train_loader)}')\n",
    "vl = next(iter(val_loader))\n",
    "print('\\nData shape for validation:')\n",
    "print(f'\\u2022 Node features: ({batch_size} \\u00D7 {vl.x.shape[0] // batch_size}, {vl.x.shape[1]}) \\u00D7 {len(val_loader)}')\n",
    "print(f'\\u2022 Edge features: ({batch_size} \\u00D7 {vl.edge_attr.shape[0] // batch_size}, {vl.edge_attr.shape[1]}) \\u00D7 {len(val_loader)}')\n",
    "print(f'\\u2022 Additional features: {tuple(vl.additional_features.shape)} \\u00D7 {len(val_loader)}')\n",
    "print(f'\\u2022 Labels: {tuple(vl.y.shape)} \\u00D7 {len(val_loader)}')\n",
    "\n",
    "# Visualize data\n",
    "sample = next(iter(train_loader))\n",
    "visualize_conn_matrix(sample, edge_modalities)\n",
    "print(\"Value ranges for connectivity matrices:\")\n",
    "for i, modality in enumerate(edge_modalities):\n",
    "    edge_attr = sample.edge_attr[:, i]\n",
    "    print(f\"\\u2022 {modality}: [{edge_attr.min():.3f}, {edge_attr.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_edge_features = len(edge_modalities)\n",
    "num_additional_features = 1 # Age\n",
    "model = get_model(model_name, num_nodes_per_graph, num_node_features, num_edge_features, num_additional_features, num_channels=num_channels).to(device)\n",
    "print(f\"Selected model: {model_name}\")\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "num_feature_extractor_params = sum(p.numel() for name, p in model.named_parameters() if p.requires_grad and not name.startswith('fc_layers'))\n",
    "num_fclayers_params = sum(p.numel() for p in model.fc_layers.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_params} = {num_feature_extractor_params} + {num_fclayers_params} for feature extractor and FC layers\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metric = Accuracy(task='binary').to(device)\n",
    "model, epoch_loss_values, epoch_metric_values, metric_values = train_model(model_dir, model, device, train_loader, val_loader,\n",
    "    logger, criterion, metric, max_epochs, learning_rate, weight_decay, val_interval, es_patience)\n",
    "plot_metric_values(model_dir, epoch_loss_values, epoch_metric_values, metric_values, val_interval)\n",
    "\n",
    "# Visualize outcome\n",
    "sample_indices = [20, 40]\n",
    "for row, sample_index in enumerate(sample_indices):\n",
    "    single_dataset = Subset(val_ds, [sample_index - 1])\n",
    "    single_loader = DataLoader(single_dataset, batch_size=1)\n",
    "    sample = next(iter(single_loader))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_data = sample.to(device)\n",
    "        output = model(batch_data)\n",
    "        pred_prob = torch.softmax(output, dim=1)\n",
    "        pred_label = torch.argmax(pred_prob, dim=1)\n",
    "    actual_label = sample.y.item()\n",
    "    title = f'Sample {sample_index}: Predicted = {\"Male\" if pred_label.item() == 1 else \"Female\"} ({pred_prob[0, pred_label].item():.2f}), Actual = {\"Male\" if actual_label == 1 else \"Female\"}'\n",
    "    visualize_conn_matrix(sample, edge_modalities, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occlusion Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occlusion_sensitivity_analysis(\n",
    "    model, \n",
    "    val_loader,\n",
    "    model_dir, \n",
    "    edge_modalities,\n",
    "    style='diverging',\n",
    "    directed=False,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "atlas_path = os.path.join(data_dir, \"BN_Atlas_246_1mm.nii.gz\")\n",
    "visualize_brain_network(model_dir, atlas_path, edge_modalities, directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = BrainConnectivityDataset(\n",
    "    data_dir=os.path.join(data_dir, \"test\"),\n",
    "    edge_modalities=edge_modalities,\n",
    "    node_modalities=node_modalities,\n",
    "    additional_variables=additional_variables,\n",
    "    scaling=scaling\n",
    ")\n",
    "test_loader, subjects = test_ds.load_data(batch_size=1, inference=True) \n",
    "pred_dir = os.path.join(model_dir, \"Prediction\")\n",
    "apply_best_model(model_dir, model, device, test_loader, pred_dir, subjects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anonymous",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
