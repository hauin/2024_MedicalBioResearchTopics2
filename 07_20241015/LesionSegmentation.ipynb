{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImage, LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Resize, Resized,\n",
        "    ScaleIntensityd,\n",
        "    RandRotate90d,\n",
        "    RandFlipd,\n",
        "    Activations,\n",
        "    AsDiscrete\n",
        ")\n",
        "from monai.networks.nets import UNet, VNet, DynUNet, AttentionUnet, ResNet, SegResNet, UNETR, SwinUNETR\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.visualize.utils import blend_images\n",
        "%env CUDA_VISIBLE_DEVICES=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions and Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_image_with_metadata(image_file):\n",
        "    loader = LoadImage(image_only=False)\n",
        "    image, metadata = loader(image_file)\n",
        "    return {\"brain\": image, \"affine\": metadata['affine'], \"original_dim\": image.shape, \"filename\": os.path.basename(image_file)}\n",
        "\n",
        "def load_data(data_dir, resize_dim, batch_size, test_size=0.2, inference=False):\n",
        "    train_transforms = [\n",
        "        LoadImaged(keys=[\"brain\", \"lesion\"], image_only=True),\n",
        "        EnsureChannelFirstd(keys=[\"brain\", \"lesion\"]),\n",
        "        ScaleIntensityd(keys=\"brain\"),\n",
        "        RandRotate90d(keys=[\"brain\", \"lesion\"], prob=0.8, spatial_axes=[0, 2]),\n",
        "        RandFlipd(keys=[\"brain\", \"lesion\"], spatial_axis=0, prob=0.5)\n",
        "    ]\n",
        "    val_transforms = [\n",
        "        LoadImaged(keys=[\"brain\", \"lesion\"], image_only=True),\n",
        "        EnsureChannelFirstd(keys=[\"brain\", \"lesion\"]),\n",
        "        ScaleIntensityd(keys=\"brain\")\n",
        "    ]\n",
        "    test_transforms = [\n",
        "        EnsureChannelFirstd(keys=\"brain\"),\n",
        "        Resized(keys=\"brain\", spatial_size=resize_dim, mode=\"trilinear\"),\n",
        "        ScaleIntensityd(keys=\"brain\")\n",
        "    ]\n",
        "    if resize_dim is not None:\n",
        "        trainval_resize_transform = Resized(keys=[\"brain\", \"lesion\"], spatial_size=resize_dim, mode=[\"trilinear\", \"nearest\"])\n",
        "        test_resize_transform = Resized(keys=\"brain\", spatial_size=resize_dim, mode=\"trilinear\")\n",
        "        train_transforms.insert(2, trainval_resize_transform)\n",
        "        val_transforms.insert(2, trainval_resize_transform)\n",
        "        test_transforms.insert(1, test_resize_transform)\n",
        "    train_transforms = Compose(train_transforms)\n",
        "    val_transforms = Compose(val_transforms)\n",
        "    test_transforms = Compose(test_transforms)\n",
        "    if not inference:\n",
        "        brains = sorted(glob.glob(os.path.join(data_dir, \"Brain\", \"*.nii.gz\")))\n",
        "        lesions = sorted(glob.glob(os.path.join(data_dir, \"Lesion\", \"*.nii.gz\")))\n",
        "        data_dicts = [\n",
        "            {\"brain\": brain_name, \"lesion\": lesion_name}\n",
        "            for brain_name, lesion_name in zip(brains, lesions)\n",
        "        ]\n",
        "        train_files, val_files = train_test_split(data_dicts, test_size=test_size, random_state=42)\n",
        "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
        "        val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "        val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "        return train_loader, val_loader\n",
        "    else:\n",
        "        brains = sorted(glob.glob(os.path.join(data_dir, \"Brain\", \"*.nii.gz\")))\n",
        "        data_dicts = [load_image_with_metadata(brain_name) for brain_name in brains]\n",
        "        test_ds = Dataset(data=data_dicts, transform=test_transforms)\n",
        "        test_loader = DataLoader(test_ds, batch_size=1, num_workers=0, pin_memory=torch.cuda.is_available()) # 추론 시 일반적으로 배치 처리의 이점이 학습 시만큼 크지 않습니다.\n",
        "        return test_loader\n",
        "\n",
        "def get_model(model_name, img_size, num_classes=1):\n",
        "    if model_name == \"UNet\":\n",
        "        return UNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            channels=(32, 64, 128, 256),\n",
        "            strides=(2, 2, 2),\n",
        "            num_res_units=2,\n",
        "        )\n",
        "    elif model_name == \"VNet\":\n",
        "        return VNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            dropout_dim=3,\n",
        "            dropout_prob_down=0.2,\n",
        "            dropout_prob_up=(0.2, 0.2, 0.2),\n",
        "        )\n",
        "    elif model_name == \"AttentionUnet\":\n",
        "        return AttentionUnet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            channels=(32, 64, 128, 256),\n",
        "            strides=(2, 2, 2),\n",
        "        )\n",
        "    elif model_name == \"SegResNet\":\n",
        "        return SegResNet(\n",
        "            spatial_dims=3,\n",
        "            init_filters=32,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            dropout_prob=0.3,\n",
        "            use_conv_final=True,\n",
        "            blocks_down=(1, 2, 2),\n",
        "            blocks_up=(1, 1),\n",
        "        )\n",
        "    elif model_name == \"UNETR\":\n",
        "        return UNETR(\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            img_size=img_size,\n",
        "            feature_size=16,\n",
        "            hidden_size=768,\n",
        "            mlp_dim=3072,\n",
        "            num_heads=12,\n",
        "            pos_embed='perceptron',\n",
        "            norm_name='instance',\n",
        "            res_block=True,\n",
        "            dropout_rate=0.1,\n",
        "        )\n",
        "    elif model_name == \"SwinUNETR\":\n",
        "        return SwinUNETR(\n",
        "            img_size=img_size,\n",
        "            in_channels=1,\n",
        "            out_channels=num_classes,\n",
        "            feature_size=24,\n",
        "            use_checkpoint=True,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
        "\n",
        "def train_one_epoch(model, device, train_loader, optimizer, criterion, scaler, metric, post_pred):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    metric.reset()\n",
        "    for batch_data in train_loader:\n",
        "        images, labels = (\n",
        "            batch_data[\"brain\"].to(device),\n",
        "            batch_data[\"lesion\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
        "            loss = criterion(outputs, labels)\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
        "        metric(y_pred=outputs, y=labels)\n",
        "    epoch_metric = metric.aggregate().item()\n",
        "    return epoch_loss / len(train_loader), epoch_metric\n",
        "\n",
        "def validate_one_epoch(model, device, val_loader, metric, post_pred):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for batch_data in val_loader:\n",
        "            images, labels = (\n",
        "                batch_data[\"brain\"].to(device),\n",
        "                batch_data[\"lesion\"].to(device),\n",
        "            )\n",
        "            outputs = model(images)\n",
        "            outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
        "            metric(y_pred=outputs, y=labels)\n",
        "    return metric.aggregate().item()\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=30, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.counter = 0\n",
        "    def __call__(self, metric):\n",
        "        score = metric\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "def train_model(model_dir, model, device, train_loader, val_loader, logger,\n",
        "        criterion, metric, post_pred, max_epochs=100, learning_rate=1e-4, weight_decay=1e-5, val_interval=1, es_patience=30):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "    start_time = time.time()\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    best_model_state = None\n",
        "    early_stopping = EarlyStopping(patience=es_patience, delta=0)\n",
        "    epoch_loss_values, epoch_metric_values, metric_values = [], [], []\n",
        "    for epoch in range(max_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_loss, epoch_metric = train_one_epoch(model, device, train_loader, optimizer, criterion, scaler, metric, post_pred)\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        epoch_metric_values.append(epoch_metric)\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            val_metric = validate_one_epoch(model, device, val_loader, metric, post_pred)\n",
        "            metric_values.append(val_metric)\n",
        "            if val_metric > best_metric:\n",
        "                best_metric = val_metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_model_state = model.state_dict()\n",
        "                torch.save(model.state_dict(), os.path.join(model_dir, \"BestMetricModel.pth\"))\n",
        "                logger.info(f\"Best DSC: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
        "            early_stopping(val_metric)\n",
        "            if early_stopping.early_stop:\n",
        "                logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
        "                print(f\"; Early stopping triggered at epoch {epoch + 1}\", end=\"\")\n",
        "                break\n",
        "        epoch_end_time = time.time()\n",
        "        logger.info(f\"Epoch {epoch + 1} completed for {(epoch_end_time - epoch_start_time)/60:.2f} mins - Training loss: {epoch_loss:.4f}, Training DSC: {epoch_metric:.4f}, Validation DSC: {val_metric:.4f}\")\n",
        "        lr_scheduler.step()\n",
        "        sys.stdout.write(f\"\\rEpoch {epoch + 1}/{max_epochs} completed\")\n",
        "        sys.stdout.flush()\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    logger.info(f\"Best DSC: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
        "    print(f\"\\nBest DSC: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "    return model, epoch_loss_values, epoch_metric_values, metric_values\n",
        "\n",
        "def plot_metric_values(model_dir, epoch_loss_values, epoch_metric_values, metric_values, val_interval=1):\n",
        "    _, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
        "    axs[0].plot( [i + 1 for i in range(len(epoch_loss_values))], epoch_loss_values, label='Training Loss', color='red')\n",
        "    axs[0].set_title('Training Loss')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[1].plot([i + 1 for i in range(len(epoch_metric_values))], epoch_metric_values, label='Training DSC', color='red')\n",
        "    axs[1].plot([val_interval * (i + 1) for i in range(len(metric_values))], metric_values, label='Validation DSC', color='blue')\n",
        "    axs[1].set_title('Training DSC vs. Validation DSC')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_ylabel('DSC')\n",
        "    axs[1].legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(model_dir, \"Performance.png\"), dpi=300)\n",
        "\n",
        "def apply_best_model(model_dir, model, device, test_loader, post_pred, pred_dir, resize_dim): \n",
        "    model.load_state_dict(torch.load(os.path.join(model_dir, \"BestMetricModel.pth\")))\n",
        "    model.eval()\n",
        "    os.makedirs(pred_dir, exist_ok=True)\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            brain = data[\"brain\"].to(device)\n",
        "            affine = data[\"affine\"][0]\n",
        "            original_dim = (*(t.item() for t in data[\"original_dim\"]),)\n",
        "            filename = data[\"filename\"][0]\n",
        "            output = model(brain)\n",
        "            output = post_pred(output[0])\n",
        "            if resize_dim is not None:\n",
        "                resize_to_original = Resize(spatial_size=original_dim, mode=\"nearest\")\n",
        "                output = resize_to_original(output)\n",
        "            nifti_image = nib.Nifti1Image(output.squeeze().detach().cpu().numpy(), affine)\n",
        "            pred_file = os.path.join(pred_dir, filename)\n",
        "            nib.save(nifti_image, pred_file)\n",
        "\n",
        "class GradCAM3D:\n",
        "    def __init__(self, model, target_layer, criterion):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        self.model.eval()\n",
        "        target_layer.register_forward_hook(self.save_activation)\n",
        "        target_layer.register_full_backward_hook(self.save_gradient)\n",
        "        self.loss = criterion\n",
        "    def save_activation(self, _module, _input, output):\n",
        "        self.activations = output.detach()\n",
        "    def save_gradient(self, _module, _grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "    def __call__(self, brain, lesion):\n",
        "        self.model.zero_grad()\n",
        "        output = self.model(brain)\n",
        "        loss = self.loss(output, lesion)\n",
        "        loss.backward()\n",
        "        gradients = self.gradients\n",
        "        activations = self.activations\n",
        "        weights = torch.mean(gradients, dim=(2, 3, 4), keepdim=True)\n",
        "        cam = torch.sum(weights * activations, dim=1, keepdim=True)\n",
        "        cam = F.relu(cam)\n",
        "        cam = F.interpolate(cam, size=brain.shape[2:], mode='trilinear', align_corners=False)\n",
        "        cam = cam - torch.min(cam)\n",
        "        cam = cam / torch.max(cam)\n",
        "        return cam.squeeze(0)\n",
        "\n",
        "def apply_gradcam_to_sample(model, val_loader, target_layers, device, criterion, sample_index, slice_index):\n",
        "    brain = val_loader.dataset[sample_index][\"brain\"].to(device) \n",
        "    lesion = val_loader.dataset[sample_index][\"lesion\"].to(device)\n",
        "    _, axes = plt.subplots(len(target_layers), 3, figsize=(12, 4 * len(target_layers)))\n",
        "    brain_slice = torch.rot90(brain[0, :, :, slice_index], k=1, dims=(0, 1))\n",
        "    lesion_slice = torch.rot90(lesion[0, :, :, slice_index], k=1, dims=(0,1))\n",
        "    for i, (layer_name, target_layer) in enumerate(target_layers.items()):\n",
        "        grad_cam = GradCAM3D(model, target_layer, criterion)\n",
        "        with torch.no_grad():\n",
        "            _ = model(brain.unsqueeze(0))\n",
        "        cam = grad_cam(brain.unsqueeze(0), lesion.unsqueeze(0))\n",
        "        cam_slice = torch.rot90(cam[0, :, :, slice_index], k=1, dims=(0,1))\n",
        "        axes[i, 0].imshow(brain_slice.detach().cpu(), cmap='gray')\n",
        "        axes[i, 0].set_title(\"Brain\")\n",
        "        axes[i, 0].axis('off')\n",
        "        axes[i, 1].imshow(lesion_slice.detach().cpu(), cmap='gray')\n",
        "        axes[i, 1].set_title(\"Lesion\")\n",
        "        axes[i, 1].axis('off')\n",
        "        axes[i, 2].imshow(brain_slice.detach().cpu(), cmap='gray')\n",
        "        axes[i, 2].imshow(cam_slice.detach().cpu(), cmap='jet', alpha=0.5)\n",
        "        axes[i, 2].set_title(f\"GradCAM: {layer_name}\")\n",
        "        axes[i, 2].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def get_target_layers(model, layer_indices=[-1]):\n",
        "    target_layers = {}\n",
        "    all_layers = list(model.modules())\n",
        "    conv_layers = [layer for layer in all_layers if isinstance(layer, (torch.nn.Conv2d, torch.nn.Conv3d))]\n",
        "    for index in layer_indices:\n",
        "        if index == -1 or index == len(conv_layers) - 1:\n",
        "            layer_index = len(conv_layers) - 1\n",
        "            layer_name = \"Final Conv\"\n",
        "        elif index < 0:\n",
        "            layer_index = len(conv_layers) + index\n",
        "            layer_name = f\"Conv {abs(index)} from End\"\n",
        "        elif index < len(conv_layers):\n",
        "            layer_index = index\n",
        "            leyer_name = f\"Conv {index}\"\n",
        "        target_layers[layer_name] = conv_layers[layer_index]\n",
        "    return target_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"LesionSegmentation_2mm\"\n",
        "model_dir_prefix = \"LesionSegmentation\"\n",
        "model_name = \"SegResNet\"  # any supported model name: UNet, VNet, AttentionUnet, SegResNet, UNETR, SwinUNETR\n",
        "num_classes = 1  # for binary segmentation\n",
        "resize_dim = (64, 64, 64)\n",
        "test_size = 0.2\n",
        "batch_size = 5\n",
        "max_epochs = 100\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "val_interval = 1\n",
        "es_patience = 30\n",
        "\n",
        "model_dir = f\"{model_dir_prefix}_{model_name}\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print('Device:', device)\n",
        "log_file = os.path.join(model_dir, \"Prediction.log\")\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(message)s\")\n",
        "logger = logging.getLogger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_determinism(seed=0)\n",
        "train_loader, val_loader = load_data(os.path.join(data_dir, \"train\"), resize_dim, batch_size, test_size)\n",
        "\n",
        "# Check data shape\n",
        "tr = first(train_loader)\n",
        "print('\\nData shape for training:')\n",
        "for key, value in tr.items():\n",
        "    print(f'\\u2022 {key}: {tuple(value.shape)} \\u00D7 {len(train_loader)}')\n",
        "    img_size = tuple(value.shape[-3:])\n",
        "vl = first(val_loader)\n",
        "print('\\nData shape for validation:')\n",
        "for key, value in vl.items():\n",
        "    print(f'\\u2022 {key}: {tuple(value.shape)} \\u00D7 {len(val_loader)}')\n",
        "\n",
        "# Visualize data\n",
        "_, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
        "brain = tr[\"brain\"][0, :, :, :, :].detach().cpu()\n",
        "lesion = tr[\"lesion\"][0, :, :, :, :].detach().cpu()\n",
        "slice_index = 29\n",
        "brain_slice = torch.rot90(brain[0, :, :, slice_index], k=1, dims=(0, 1))\n",
        "lesion_slice = torch.rot90(lesion[0, :, :, slice_index], k=1, dims=(0,1))\n",
        "blended = blend_images(brain, lesion, alpha=0.5)\n",
        "blended_slice = torch.rot90(blended[0, :, :, slice_index], k=1, dims=(0,1)).squeeze()\n",
        "axs[0].imshow(brain_slice, cmap='gray')\n",
        "axs[0].set_title(\"Brain\")\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(lesion_slice, cmap='gray')\n",
        "axs[1].set_title(\"Lesion\")\n",
        "axs[1].axis('off')\n",
        "axs[2].imshow(blended_slice, cmap='gray')\n",
        "axs[2].set_title(\"Lesion-overlaied Brain\")\n",
        "axs[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model(model_name, img_size, num_classes).to(device)\n",
        "print(f\"Selected model: {model_name}\")\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Number of trainable parameters: {num_params}\")\n",
        "\n",
        "criterion = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, sigmoid=True)\n",
        "metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "model, epoch_loss_values, epoch_metric_values, metric_values = train_model(model_dir, model, device, train_loader, val_loader, logger,\n",
        "    criterion, metric, post_pred, max_epochs, learning_rate, weight_decay, val_interval)\n",
        "plot_metric_values(model_dir, epoch_loss_values, epoch_metric_values, metric_values, val_interval)\n",
        "\n",
        "# Visualize outcome\n",
        "sample_index = 5\n",
        "slice_index = 32\n",
        "model.eval()\n",
        "metric.reset()\n",
        "with torch.no_grad():\n",
        "    brain = val_loader.dataset[sample_index][\"brain\"].to(device)\n",
        "    lesion = val_loader.dataset[sample_index][\"lesion\"].to(device)\n",
        "    output = model(brain.unsqueeze(0))\n",
        "    output = post_pred(output).squeeze(0)\n",
        "    metric(y_pred=output, y=lesion)\n",
        "sample_metric = metric.aggregate().item()\n",
        "_, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
        "brain_slice = torch.rot90(brain[0, :, :, slice_index], k=1, dims=(0, 1))\n",
        "lesion_slice = torch.rot90(lesion[0, :, :, slice_index], k=1, dims=(0,1))\n",
        "output_slice = torch.rot90(output[0, :, :, slice_index], k=1, dims=(0,1))\n",
        "axs[0].imshow(brain_slice.detach().cpu(), cmap=\"gray\")\n",
        "axs[0].set_title(\"Brain\")\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(lesion_slice.detach().cpu(), cmap=\"gray\")\n",
        "axs[1].set_title(\"Lesion\")\n",
        "axs[1].axis('off')\n",
        "axs[2].imshow(output_slice.detach().cpu(), cmap=\"gray\")\n",
        "axs[2].set_title(f\"Predicted Lesion: DSC = {sample_metric:.3f}\")\n",
        "axs[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GradCAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_index = 5 \n",
        "slice_index = 32\n",
        "# target_layers = get_target_layers(model)\n",
        "target_layers = {\n",
        "    \"Encoder Last\": model.down_layers[-1][-1],\n",
        "    \"Decoder First\": model.up_layers[0][0],\n",
        "    \"Final Conv\": model.conv_final[-1]\n",
        "}\n",
        "apply_gradcam_to_sample(model, val_loader, target_layers, device, criterion, sample_index, slice_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loader = load_data(os.path.join(data_dir, \"test\"), resize_dim, None, None, True)\n",
        "pred_dir = os.path.join(model_dir, \"Prediction\")\n",
        "apply_best_model(model_dir, model, device, test_loader, post_pred, pred_dir, resize_dim)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Anonymous",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
