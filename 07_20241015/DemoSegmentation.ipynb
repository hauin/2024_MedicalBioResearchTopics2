{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import time\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from monai.data import create_test_image_3d, Dataset, DataLoader, decollate_batch\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    ScaleIntensityd,\n",
        "    RandRotate90d,\n",
        "    RandFlipd,\n",
        "    Activations,\n",
        "    AsDiscrete\n",
        ")\n",
        "from monai.networks.nets import UNet\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.visualize.utils import blend_images\n",
        "%env CUDA_VISIBLE_DEVICES=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Functions and Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data(data_dir, sim_dim = (64, 64, 64), num_images=40):\n",
        "    os.makedirs(os.path.join(data_dir, \"Image\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(data_dir, \"Label\"), exist_ok=True)\n",
        "    for i in range(num_images):\n",
        "        img, lbl = create_test_image_3d(sim_dim[0], sim_dim[1], sim_dim[2], rad_min=3, rad_max=6, num_seg_classes=1, random_state=np.random.RandomState(42))\n",
        "        n = nib.Nifti1Image(img, np.eye(4))\n",
        "        nib.save(n, os.path.join(data_dir, \"Image\", f\"{i:03d}.nii.gz\"))\n",
        "        n = nib.Nifti1Image(lbl, np.eye(4))\n",
        "        nib.save(n, os.path.join(data_dir, \"Label\", f\"{i:03d}.nii.gz\"))\n",
        "    images = sorted(glob.glob(os.path.join(data_dir, \"Image\", \"*.nii.gz\")))\n",
        "    labels = sorted(glob.glob(os.path.join(data_dir, \"Label\", \"*.nii.gz\")))\n",
        "    data_dicts = [\n",
        "        {\"image\": image_name, \"label\": label_name}\n",
        "        for image_name, label_name in zip(images, labels)\n",
        "    ]\n",
        "    print(f\"{num_images} images and labels with {sim_dim[0]} \\u00D7 {sim_dim[1]} \\u00D7 {sim_dim[2]} dimensions simulated\")\n",
        "    return data_dicts\n",
        "\n",
        "def load_data(data_dicts, batch_size, test_size=10):\n",
        "    train_transforms = Compose([\n",
        "        LoadImaged(keys=[\"image\", \"label\"], image_only=True),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        ScaleIntensityd(keys=\"image\"),\n",
        "        RandRotate90d(keys=[\"image\", \"label\"], prob=0.8, spatial_axes=[0, 2]),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], spatial_axis=0, prob=0.5),\n",
        "    ])\n",
        "    val_transforms = Compose([\n",
        "        LoadImaged(keys=[\"image\", \"label\"], image_only=True),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        ScaleIntensityd(keys=\"image\"),\n",
        "    ])\n",
        "    train_files, val_files = train_test_split(data_dicts, test_size=test_size, random_state=42)\n",
        "    train_ds = Dataset(data=train_files, transform=train_transforms)\n",
        "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=0, pin_memory=torch.cuda.is_available())\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def train_one_epoch(model, device, train_loader, optimizer, criterion, scaler, metric, post_pred):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    metric.reset()\n",
        "    for batch_data in train_loader:\n",
        "        images, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
        "            loss = criterion(outputs, labels)\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
        "        metric(y_pred=outputs, y=labels)\n",
        "    epoch_metric = metric.aggregate().item()\n",
        "    return epoch_loss / len(train_loader), epoch_metric\n",
        "\n",
        "def validate_one_epoch(model, device, val_loader, metric, post_pred):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for batch_data in val_loader:\n",
        "            images, labels = (\n",
        "                batch_data[\"image\"].to(device),\n",
        "                batch_data[\"label\"].to(device),\n",
        "            )\n",
        "            outputs = model(images)\n",
        "            outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
        "            metric(y_pred=outputs, y=labels)\n",
        "    return metric.aggregate().item()\n",
        "\n",
        "def train_model(model_dir, model, device, train_loader, val_loader, logger,\n",
        "        criterion, metric, post_pred, max_epochs=100, learning_rate=1e-4, weight_decay=1e-5, val_interval=1):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "    start_time = time.time()\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    best_model_state = None\n",
        "    epoch_loss_values, epoch_metric_values, metric_values = [], [], []\n",
        "    for epoch in range(max_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_loss, epoch_metric = train_one_epoch(model, device, train_loader, optimizer, criterion, scaler, metric, post_pred)\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        epoch_metric_values.append(epoch_metric)\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            val_metric = validate_one_epoch(model, device, val_loader, metric, post_pred)\n",
        "            metric_values.append(val_metric)\n",
        "            if val_metric > best_metric:\n",
        "                best_metric = val_metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_model_state = model.state_dict()\n",
        "                torch.save(model.state_dict(), os.path.join(model_dir, \"BestMetricModel.pth\"))\n",
        "                logger.info(f\"Best DSC: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
        "        epoch_end_time = time.time()\n",
        "        logger.info(f\"Epoch {epoch + 1} completed for {(epoch_end_time - epoch_start_time)/60:.2f} mins - Training loss: {epoch_loss:.4f}, Training DSC: {epoch_metric:.4f}, Validation DSC: {val_metric:.4f}\")\n",
        "        sys.stdout.write(f\"\\rEpoch {epoch + 1}/{max_epochs} completed\")\n",
        "        sys.stdout.flush()\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    logger.info(f\"Best DSC: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
        "    print(f\"Best DSC: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "    return model, epoch_loss_values, epoch_metric_values, metric_values\n",
        "\n",
        "def plot_metric_values(model_dir, epoch_loss_values, epoch_metric_values, metric_values, val_interval=1):\n",
        "    _, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
        "    axs[0].plot( [i + 1 for i in range(len(epoch_loss_values))], epoch_loss_values, label='Training Loss', color='red')\n",
        "    axs[0].set_title('Training Loss')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[1].plot([i + 1 for i in range(len(epoch_metric_values))], epoch_metric_values, label='Training DSC', color='red')\n",
        "    axs[1].plot([val_interval * (i + 1) for i in range(len(metric_values))], metric_values, label='Validation DSC', color='blue')\n",
        "    axs[1].set_title('Training DSC vs. Validation DSC')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_ylabel('DSC')\n",
        "    axs[1].legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(model_dir, \"Performance.png\"), dpi=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"Demo\"\n",
        "model_dir_prefix = \"Demo\"\n",
        "sim_dim = (64, 64, 64)\n",
        "num_images = 40\n",
        "test_size = 10\n",
        "batch_size = 5\n",
        "max_epochs = 100\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 1e-5\n",
        "val_interval = 1\n",
        "\n",
        "model_dir = f\"{model_dir_prefix}_UNet\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print('Device:', device)\n",
        "log_file = os.path.join(model_dir, \"Prediction.log\")\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(message)s\")\n",
        "logger = logging.getLogger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_determinism(seed=0)\n",
        "data_dicts = create_data(data_dir, sim_dim, num_images)\n",
        "train_loader, val_loader = load_data(data_dicts, batch_size, test_size)\n",
        "\n",
        "# Check data shape\n",
        "tr = first(train_loader)\n",
        "print('\\nData shape for training:')\n",
        "for key, value in tr.items():\n",
        "    print(f'\\u2022 {key}: {list(value.shape)} \\u00D7 {len(train_loader)}')\n",
        "vl = first(val_loader)\n",
        "print('\\nData shape for validation:')\n",
        "for key, value in vl.items():\n",
        "    print(f'\\u2022 {key}: {list(value.shape)} \\u00D7 {len(val_loader)}')\n",
        "\n",
        "# Visualize data\n",
        "_, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
        "image = tr[\"image\"][0, :, :, :, :].detach().cpu()\n",
        "label = tr[\"label\"][0, :, :, :, :].detach().cpu()\n",
        "middle_index = image.shape[3] // 2\n",
        "image_slice = image[0, :, :, middle_index]\n",
        "label_slice = label[0, :, :, middle_index]\n",
        "blended = blend_images(image, label, alpha=0.5)\n",
        "blended_slice = blended[0, :, :, middle_index]\n",
        "axs[0].imshow(image_slice, cmap='gray')\n",
        "axs[0].set_title(\"Image\")\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(label_slice, cmap='gray')\n",
        "axs[1].set_title(\"Label\")\n",
        "axs[1].axis('off')\n",
        "axs[2].imshow(blended_slice, cmap='gray')\n",
        "axs[2].set_title(\"Label-overlaid Image\")\n",
        "axs[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        ").to(device)\n",
        "criterion = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, sigmoid=True)\n",
        "metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "model, epoch_loss_values, epoch_metric_values, metric_values = train_model(model_dir, model, device, train_loader, val_loader, logger,\n",
        "    criterion, metric, post_pred, max_epochs, learning_rate, weight_decay, val_interval)\n",
        "plot_metric_values(model_dir, epoch_loss_values, epoch_metric_values, metric_values, val_interval)\n",
        "\n",
        "# Visualize outcome\n",
        "sample_index = 5\n",
        "slice_index = 16\n",
        "model.eval()\n",
        "metric.reset()\n",
        "with torch.no_grad():\n",
        "    image = val_loader.dataset[sample_index][\"image\"].to(device)\n",
        "    label = val_loader.dataset[sample_index][\"label\"].to(device)\n",
        "    output = model(image.unsqueeze(0))\n",
        "    output = post_pred(output.squeeze(0))\n",
        "    metric(y_pred=output, y=label)\n",
        "metric_value = metric.aggregate().item()\n",
        "_, axs = plt.subplots(1, 3, figsize=(12, 5))\n",
        "axs[0].imshow(image[0,:, :, slice_index].detach().cpu(), cmap=\"gray\")\n",
        "axs[0].set_title(\"Image\")\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(label[0,:, :, slice_index].detach().cpu(), cmap=\"gray\")\n",
        "axs[1].set_title(\"Label\")\n",
        "axs[1].axis('off')\n",
        "axs[2].imshow(output[0,:, :, slice_index].detach().cpu(), cmap=\"gray\")\n",
        "axs[2].set_title(f\"Predicted Label: DSC = {metric_value:.3f}\")\n",
        "axs[2].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Anonymous",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
